<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>MCP on Hyunjae Blog</title>
    <link>https://hyunjae-labs.github.io/tags/mcp/</link>
    <description>Recent content in MCP on Hyunjae Blog</description>
    <generator>Hugo -- 0.148.2</generator>
    <language>ko-kr</language>
    <lastBuildDate>Sun, 03 Aug 2025 07:27:30 +0900</lastBuildDate>
    <atom:link href="https://hyunjae-labs.github.io/tags/mcp/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>SuperGemini 개발 일지: SuperClaude 아키텍처 분석과 포팅</title>
      <link>https://hyunjae-labs.github.io/posts/supergemini-development-journey/</link>
      <pubDate>Sun, 03 Aug 2025 07:27:30 +0900</pubDate>
      <guid>https://hyunjae-labs.github.io/posts/supergemini-development-journey/</guid>
      <description>LLM 평가 시스템을 만들던 중 SuperClaude를 발견하고 Gemini용으로 포팅한 과정</description>
      <content:encoded><![CDATA[<h2 id="배경-llm-평가에-대한-관심">배경: LLM 평가에 대한 관심</h2>
<p>나는 평소 LLM과 프롬프트 평가에 관심이 많아서 <strong>자체 LLM 평가 시스템</strong>을 개발해 사용하고 있었다. 이 시스템은 Claude의 서로 다른 프롬프트 전략을 자동으로 비교 평가하는 도구로, Promptfoo 프레임워크를 기반으로 한다:</p>
<p><strong>평가 데이터 소스</strong>:</p>
<ul>
<li><strong>학습 데이터 이후 문제</strong>: Codeforces Round 1036/1037 (2025년 7월), AtCoder World Tour Finals (2025년 7월) 등 Claude 학습 컷오프 이후 출제된 문제들</li>
<li><strong>다영역 벤치마크</strong>: 알고리즘 구현, 시스템 설계, 논리 추론, 데이터 분석 등 실무 중심 문제</li>
</ul>
<p><strong>평가 방식</strong>:</p>
<ul>
<li><strong>자동 코드 검증</strong>: Python 실행으로 정답률 측정 (테스트 케이스 자동 실행)</li>
<li><strong>LLM 기반 채점</strong>: OpenAI GPT가 응답 품질을 1-10점으로 상세 평가</li>
<li><strong>객관적 기준</strong>: 사전 정의된 채점 루브릭으로 편향 최소화</li>
</ul>
<p>이 시스템을 통해 프롬프트 성능을 객관적으로 측정하고 개선하는 것이 매우 흥미로웠다.</p>
<hr>
<h2 id="superclaude-발견">SuperClaude 발견</h2>
<p>그러던 중 <strong>SuperClaude</strong>라는 참신한 시스템을 알게 되었다. Claude CLI를 확장하여 전문화된 명령어와 페르소나 시스템을 제공하는 프레임워크였다. 이 아키텍처가 정말 인상적이었다:</p>
<ul>
<li>17개의 전문 명령어 시스템</li>
<li>도메인별 페르소나 (architect, frontend, backend 등)</li>
<li>MCP 서버 통합</li>
<li>체계적인 워크플로우 관리</li>
</ul>
<h2 id="gemini-버전의-필요성">Gemini 버전의 필요성</h2>
<p>나는 Gemini-CLI도 종종 사용하는데, 이런 시스템이 Gemini에는 없었다. <strong>&ldquo;Gemini에서도 이걸 사용할 수 있다면?&rdquo;</strong> 하는 생각이 들었다.</p>
<p>그래서 SuperClaude의 아키텍처를 분석하고 Gemini CLI에 맞게 적응시키기 시작했다.</p>
<hr>
<h2 id="개발-과정">개발 과정</h2>
<h3 id="1-아키텍처-분석">1. 아키텍처 분석</h3>
<p>SuperClaude의 구조를 파악하고 Gemini CLI의 차이점을 분석:</p>
<ul>
<li>Claude CLI: JSON 기반 설정</li>
<li>Gemini CLI: TOML 기반 명령어 시스템</li>
</ul>
<h3 id="2-핵심-기능-포팅">2. 핵심 기능 포팅</h3>
<ul>
<li>17개 명령어 시스템 (<code>/sg:</code> 접두사로 변경)</li>
<li>페르소나 시스템 완전 이식</li>
<li>플래그 시스템 호환성 확보</li>
</ul>
<h3 id="3-호환성-문제-해결">3. 호환성 문제 해결</h3>
<p><strong>Thinking Budget System</strong>:
Claude의 <code>--think</code> 플래그는 Gemini API에서 작동하지 않아서 제거</p>
<p><strong>Magic MCP 호환성 문제</strong>:
Gemini API 함수명 규칙과 충돌이 있어서 현재는 <strong>비활성화</strong> 상태로 설정:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># setup.py에서 기본적으로 disabled</span>
</span></span><span style="display:flex;"><span>magic_mcp_enabled <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span></code></pre></div><p>필요시 사용자가 수동으로 활성화할 수 있도록 설정 옵션 제공.</p>
<hr>
<h2 id="오픈소스-배포">오픈소스 배포</h2>
<p>개발이 완료된 후, <strong>혼자만 사용하기 아까운 시스템</strong>이라는 생각이 들었다.</p>
<h3 id="mit-license로-배포">MIT License로 배포</h3>
<ul>
<li>GitHub: <a href="https://github.com/SuperGemini-Org/SuperGemini_Framework">SuperGemini-Org/SuperGemini_Framework</a></li>
<li>PyPI: <code>pip install SuperGemini</code></li>
<li>원본 SuperClaude에 대한 적절한 attribution 포함</li>
</ul>
<h3 id="설치-및-사용">설치 및 사용</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>pip install SuperGemini
</span></span><span style="display:flex;"><span>python -m SuperGemini install
</span></span></code></pre></div><h2 id="현재-상태">현재 상태</h2>
<p><strong>v3.1.2</strong> 기준:</p>
<ul>
<li>✅ 17개 명령어 완전 작동</li>
<li>✅ 페르소나 시스템 정상 동작</li>
<li>✅ Context7, Sequential, Playwright MCP 연동</li>
<li>⚠️ Magic MCP는 호환성 문제로 비활성화</li>
<li>✅ PyPI 배포 완료</li>
</ul>
<hr>
<h2 id="배운-점">배운 점</h2>
<ol>
<li><strong>오픈소스의 가치</strong>: 좋은 아이디어는 다른 플랫폼으로도 확장될 수 있다</li>
<li><strong>API 차이점</strong>: Claude와 Gemini의 함수명 규칙 차이가 생각보다 중요했다</li>
<li><strong>기술적 호환성</strong>: 서로 다른 AI 플랫폼 간의 차이점을 이해하게 되었다</li>
</ol>
<h2 id="향후-계획">향후 계획</h2>
<ul>
<li>Magic MCP 호환성 문제 해결</li>
<li>사용자 피드백 반영</li>
<li>Gemini 특화 기능 추가 검토</li>
</ul>
<hr>
<p><strong>결론</strong>: LLM 평가에 대한 개인적 관심이 의미있는 오픈소스 프로젝트로 발전했다. SuperClaude 팀에게 감사하며, Gemini 사용자들에게도 도움이 되길 바란다.</p>
]]></content:encoded>
    </item>
  </channel>
</rss>
